{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uxsim import *\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import time \n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "\n",
    "seed = None\n",
    "\n",
    "W = World(\n",
    "    name=\"\",\n",
    "    deltan=5,\n",
    "    tmax=3600, #1 hour simulation\n",
    "    print_mode=1, save_mode=0, show_mode=1,\n",
    "    random_seed=seed,\n",
    "    duo_update_time=600\n",
    ")\n",
    "random.seed(seed)\n",
    "\n",
    "# network definition\n",
    "\"\"\"\n",
    "    N1  N2  N3  N4 \n",
    "    |   |   |   |\n",
    "W1--I1--I2--I3--I4-<E1\n",
    "    |   |   |   |\n",
    "    v   ^   v   ^\n",
    "    S1  S2  S3  S4\n",
    "\"\"\"\n",
    "\n",
    "signal_time = 20\n",
    "sf_1=1\n",
    "sf_2=1\n",
    "\n",
    "I1 = W.addNode(\"I1\", 1, 0, signal=[signal_time*sf_1,signal_time*sf_2])\n",
    "I2 = W.addNode(\"I2\", 2, 0, signal=[signal_time*sf_1,signal_time*sf_2])\n",
    "I3 = W.addNode(\"I3\", 3, 0, signal=[signal_time*sf_1,signal_time*sf_2])\n",
    "I4 = W.addNode(\"I4\", 4, 0, signal=[signal_time*sf_1,signal_time*sf_2])\n",
    "W1 = W.addNode(\"W1\", 0, 0)\n",
    "E1 = W.addNode(\"E1\", 5, 0)\n",
    "N1 = W.addNode(\"N1\", 1, 1)\n",
    "N2 = W.addNode(\"N2\", 2, 1)\n",
    "N3 = W.addNode(\"N3\", 3, 1)\n",
    "N4 = W.addNode(\"N4\", 4, 1)\n",
    "S1 = W.addNode(\"S1\", 1, -1)\n",
    "S2 = W.addNode(\"S2\", 2, -1)\n",
    "S3 = W.addNode(\"S3\", 3, -1)\n",
    "S4 = W.addNode(\"S4\", 4, -1)\n",
    "\n",
    "#E <-> W direction: signal group 0\n",
    "for n1,n2 in [[W1, I1], [I1, I2], [I2, I3], [I3, I4], [I4, E1]]:\n",
    "    W.addLink(n2.name+n1.name, n2, n1, length=500, free_flow_speed=50, jam_density=0.2, number_of_lanes=3, signal_group=0)\n",
    "    \n",
    "#N -> S direction: signal group 1\n",
    "for n1,n2 in [[N1, I1], [I1, S1], [N3, I3], [I3, S3]]:\n",
    "    W.addLink(n1.name+n2.name, n1, n2, length=500, free_flow_speed=30, jam_density=0.2, signal_group=1)\n",
    "\n",
    "#S -> N direction: signal group 2\n",
    "for n1,n2 in [[N2, I2], [I2, S2], [N4, I4], [I4, S4]]:\n",
    "    W.addLink(n2.name+n1.name, n2, n1, length=500, free_flow_speed=30, jam_density=0.2, signal_group=1)\n",
    "    \n",
    "\n",
    "# random demand definition every 30 seconds\n",
    "dt = 30\n",
    "demand = 2 #average demand for the simulation time\n",
    "demands = []\n",
    "for t in range(0, 3600, dt):\n",
    "    dem = random.uniform(0, demand)\n",
    "    for n1, n2 in [[N1, S1], [S2, N2], [N3, S3], [S4, N4]]:\n",
    "        W.adddemand(n1, n2, t, t+dt, dem*0.25)\n",
    "        demands.append({\"start\":n1.name, \"dest\":n2.name, \"times\":{\"start\":t,\"end\":t+dt}, \"demand\":dem})\n",
    "    for n1, n2 in [[E1, W1], [N1, W1], [S2, W1], [N3, W1],[S4, W1]]:\n",
    "        W.adddemand(n1, n2, t, t+dt, dem*0.75)\n",
    "        demands.append({\"start\":n1.name, \"dest\":n2.name, \"times\":{\"start\":t,\"end\":t+dt}, \"demand\":dem})\n",
    "\n",
    "W.exec_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W.analyzer.vehicles_to_pandas().to_csv('vehicle_data.csv')\n",
    "df_vehicles = W.analyzer.vehicles_to_pandas()\n",
    "df_vehicles.rename(columns = {'dest':'destination'}, inplace = True)\n",
    "df_vehicles.rename(columns = {'orig':'origin'}, inplace = True)\n",
    "df_vehicles.rename(columns = {'t':'time'}, inplace = True)\n",
    "df_vehicles.rename(columns = {'x':'potition'}, inplace = True)\n",
    "df_vehicles.rename(columns = {'s':'spacing'}, inplace = True)\n",
    "df_vehicles.rename(columns = {'v':'speed'}, inplace = True)\n",
    "df_vehicles = df_vehicles.drop('dn', axis=1)\n",
    "df_vehicles = df_vehicles.sort_values(by=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "producer = KafkaProducer(\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "print(f'Producer started: {time.strftime(\"%d/%m/%Y %H:%M:%S\", time.localtime())}')\n",
    "\n",
    "cnt_sec = 0 \n",
    "while cnt_sec < 3600:\n",
    "    resDf = df_vehicles.loc[(df_vehicles['time'] == cnt_sec) & (df_vehicles['link'] != 'waiting_at_origin_node')].copy()\n",
    "    resDf['time'] = pd.Timestamp.today().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    resDf.apply(lambda row: producer.send('vehicle_positions', json.loads(row.to_json())), axis=1)\n",
    "    time.sleep(5)\n",
    "    cnt_sec += 5\n",
    "    \n",
    "producer.flush()\n",
    "print(f'Producer ended: {time.strftime(\"%d/%m/%Y %H:%M:%S\", time.localtime())}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
